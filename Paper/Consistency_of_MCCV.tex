\documentclass[Research_Module_ES.tex]{subfiles}
\begin{document}
\subsection{The Monte Carlo CV($n_\nu$)}
The \textit{Monte Carlo CV($n_\nu$)}, denoted by \textit{MCCV($n_\nu$)}, is another variant of the \textit{CV($n_\nu$)} method and heavily related to the $BICV(n_v)$. It only distinguish to $BICV(n_v)$ by the way how it chooses its set of partitions. Indeed it does not choose them by a combinatorial procedure as described in the section before, this process is subjected to a random choice. Therefore it draws its subset of all possible partitions for a given $n_\nu$, which is denoted by $\mathcal{R}$, randomly with or without a replacement. $\mathcal{R}$ is the a collection of subsets such that $|\mathcal{R}|\equiv b$. This reminds to the $BICV(n_v)$, but without selecting $\mathcal{R}$ according to the \textit{balance conditions}. Therefore the \textit{MCCV($n_\nu$)} can be used as an alternative, if the collection of partitions $\mathcal{B}$ with its certain properties that have to be fulfilled is not provided. The \textit{MCCV($n_\nu$)} method does model selection by 
\begin{align*}
MCCV(n_\nu)=\min_{\alpha\in\mathcal{A}}\hat{\Gamma}_{\alpha,n}^{MCCV}
\end{align*}
where $\hat{\Gamma}_{\alpha,n}^{MCCV}$ is the estimator. While the estimator is referring again to Definition \ref{estimator CV(n_v)} and constructed similar to $\hat{\Gamma}_{\alpha,n}^{BICV}$ with the only difference that it uses $\mathcal{R}$ instead of $\mathcal{B}$. Thus we get the following form
\begin{align*}
\hat{\Gamma}_{\alpha,n}^{MCCV}=|\mathcal{R}|^{-1}n_\nu^{-1}\sum_{s\in\mathcal{R}}\parallel y_s-\hat{y}_{\alpha,s^c}\parallel^2
\end{align*}
Similar as for the $BICV(n_\nu)$ we can proof the following Theorem\footnote{Proof of Theorem \ref{THM_Consistency_MCCV} is given in Appendix A.5}. 
\begin{thm}[Asymptotic Properties of $MCCV(n_v)$]
\label{THM_Consistency_MCCV}
Under the conditions of Theorem \ref{THM_Consistency of $CV(1)$} and
\begin{align*}
\max_{s\in \mathcal{R}}\biggl\lVert \frac{1}{n_v}\sum_{i\in s}x_ix_i' - \frac{1}{n-n_v}\sum_{i\in s^c}x_ix_i'\biggr\rVert =o_P(1)
\end{align*}
where $\mathcal{R}$ contains $b$ subsets selected randomly with $b$ satisfying
\begin{align}
\frac{n^2}{b(n-n_v)^2}\to 0.\quad\textrm{and}\quad b\ge n.\label{MCCV_b_condition}
\end{align}
Suppose furthermore that $n_v$ is selected such that
\begin{align}
\frac{n_v}{n}\to 1 \quad \textrm{and} \quad n-n_v \to \infty\label{growth_rates_nv_MCCV}
\end{align}
Then the following holds
\begin{enumerate}[(I)]
\item If $\mathcal{M}_\alpha$ is in Category I, then there exists $R_n \ge 0$ such that $\hat{\Gamma}_{\alpha,n}^{MCCV} = \frac{1}{n_vb}\sum_{s\in \mathcal{R}}\varepsilon_s'\varepsilon_s + \Delta_{\alpha,n} + R_n + o_P(1)$.
\item If $\mathcal{M}_\alpha$ is in Category II, then $\hat{\Gamma}_{\alpha,n}^{MCCV} = \frac{1}{n_vb}\sum_{s\in \mathcal{R}}\varepsilon_s'\varepsilon_s + \frac{1}{n-n_v}d_\alpha\sigma^2  + o_P((n-n_v)^{-1})$.
\item $\lim_{n\to\infty}P(\mathcal{M}_{MCCV}=\mathcal{M}_\ast) = 1$
\end{enumerate}
where $\mathcal{M}_{MCCV}$ denotes the model selected by using $MCCV(n_v)$.
\end{thm}
Condition (\ref{MCCV_b_condition}) ensures that $\mathcal{R}$ converges to a \textit{Balanced Incomplete Block Design}, such that the problem of $MCCV(n_\nu)$ reduces to the problem of $BICV(n_\nu)$. Hence, it consistently estimates the optimal model. 
\end{document}